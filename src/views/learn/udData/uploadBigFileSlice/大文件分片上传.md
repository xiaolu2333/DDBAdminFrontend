# 一，大文件上传系统

1. 通过文件切片的方式，将大文件切片成小文件
2. 将小文件上传到服务器
3. 服务器接收到完小文件后，将小文件合并成大文件

# 二，三个步骤中的问题与处理方式

## 1. 文件切片

1，这里使用原生 html 的 <input type="file"> 元素来获取文件，并通过绑定 change 事件确保始终获取最新选择的文件对象：

```html
选择文件<input type="file" @change="handleFileChange">
```

在 chenge 事件的参数 event 中，可以通过 event.target.files 获取到文件对象列表，这里我们只需要获取其中的第一个文件对象，所以可以通过
event.target.files[0] 来获取到指定的文件对象。

```javascript
function handleFileChange(event) {
    console.log('event:', event)
    state.fileObj = event.target.files[0];

    // 切片
    sliceFileObj()
}
```

2，拿到文件对象后，我们需要将文件切片。
所谓的切片：就是对文件进行分割，即将文件分割成若干个小文件。这里我们使用原生的 File 对象的 slice 方法来进行切片：

```javascript
// 文件对象切片
const sliceFileObj = () => {
    const fileName = state.fileObj.name
    const fileSize = state.fileObj.size
    const fileType = state.fileObj.type

    let chunkSize = 1024 * 1024 * 2; // 每个切片的大小（2MB）
    let start = 0; // 切片的起始位置
    let chunk = 0; // 切片大小

    state.fileSliceList = []

    while (start < fileSize) {

        if (start + chunkSize <= fileSize) {
            state.fileSliceList.push({
                start: start,
                end: start + chunkSize,
                size: chunkSize,
                obj: state.fileObj.slice(start, start + chunkSize)
            })
        } else {
            state.fileSliceList.push({
                start: start,
                end: fileSize,
                size: fileSize - start,
                obj: state.fileObj.slice(start, fileSize - start)
            })
        }

        start += chunkSize
    }
}
```

这里我们将所有小切片放入到一个数组当中，方便后续使用。

## 2. 小文件上传

现在我们已经将大文件切片成了若干个小文件，接下来我们需要将这些小文件上传到服务器。
最简单的方法就是有多少个小文件就发送多少个请求：

```javascript
// 上传文件
const startUploadFile = async () => {
    state.fileSliceList.forEach(item => {
        const formData = new FormData();
        formData.append('file', item.chunk);
        formData.append('filename', item.fileName);
        formData.append('chunkSize', item.chunkSize.toString());

        uploadBigFileSliceApi(formData, start, chunkSize, fileSize).then(res => {
            console.log('response: ', response)
            if (response.data.code === 200) {
                // 文件上传完成
                state.percentage = 100;
                state.progressStatus = 'success'
            }
        })
    })
}
```

但这样有几个问题：

1. 相较于发送一个大文件，通过多次请求发送小文件会增加额外的网络传输开销
2. 由于网络原因，可能会导致小文件的上传顺序与切片顺序不一致，这样在服务器接收到所有小文件后，需要对小文件进行排序，再进行合并，这样会增加服务器的处理开销
3. 由于网络原因，尽管服务器收到了我们的小文件，但是无法保证每个小文件的完整性，时的 2 的问题扩大

因此在传输签文件之前，我们需要对小文件进行 hash 计算：

> 在文件分片上传过程中，对小文件计算hash值的主要目的是确保数据的完整性和一致性。
> 通过计算每个小文件的hash值，可以在上传和下载过程中验证文件是否被篡改或损坏。
> 如果某个小文件的hash值与预期的不一致，就可以立即发现数据的问题，从而确保数据的准确性和安全性。
> 这种数据完整性验证的机制可以在文件分片上传过程中提供额外的保障，帮助确保文件的完整性和可靠性。

1，计算文件的 hash 值

```javascript
function handleFileChange(event) {
    // ...

    // 计算 hash
    calculateHash()
}


const calculateHash = () => {
    // 分片 hash，直接读取文件内容来生成 md5 值
    state.fileSliceList.forEach((item) => {
        let sparkMD5 = new SparkMD5()
        let reader = new FileReader()
        reader.readAsText(item.obj)
        reader.onload = (event) => {
            console.log('event:', event)

            //获取文件MD5
            let str = event.target.result
            sparkMD5.append(str)
            item.hash = sparkMD5.end()
        }
    })
}
```

这里我们通过 FileReader 对象来读取文件内容，然后通过 SparkMD5 对象根据文件内容来计算文件的 hash 值。

2，上传分片文件
这里我们通过并发请求的方式来上传文件。
但是这个并发的数量应该是有限制的，并发数和分片数之间的关系是：并发数 <= 分片数。因为如果文件太大，分片数太多，那么并发数太多会导致服务器压力过大，甚至会导致服务器崩溃。

```javascript
const concurrentUpload = () => {
    let concurrent = 6 // 并发数
    let index = 0 // 当前上传的索引
    let len = fileSliceList.length // 文件切片的长度

    let promiseList = []

    while (index < len) {
        let promise = uploadFile(index)
        promiseList.push(promise)

        if (promiseList.length === concurrent || index === len - 1) {
            Promise.all(promiseList).then((res) => {
                console.log('res:', res)
            })

            promiseList = []
        }

        index++
    }
}
```

在后端，我们需要讲这些小分片保存下来：
```python
# 大文件分片上传
@csrf_exempt
def upload_big_file_slice(request):
    if request.method == 'POST':
        file = request.FILES['file']

        start = request.POST.get('start')
        end = request.POST.get('end')
        total = request.POST.get('size')
        index = request.POST.get('index')
        file = request.FILES.get('file')
        hash_value = request.POST.get('hash')
        file_name = request.POST.get('fileName')

        save_dir = os.path.join(BASE_DIR, 'static', 'uploadFiles', 'temp', 'files', f'{file_name.split(".")[0]}')
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
        with open(os.path.join(save_dir, f'{hash_value}-----{index}.part'), 'wb') as f:
            f.write(file.read())
        return JsonResponse({
            'code': 200,
            'status': 'success',
            'msg': '分片上传成功',
            'data': {
                'start': start,
                'end': end,
                'total': total,
                'index': index,
                'hash': hash_value,
                'fileName': file_name
            }
        })
    else:
        return JsonResponse({
            'code': 405,
            'msg': '请求方式错误',
            'data': None,
            'success': False
        })
```