# 一，大文件上传系统

1. 通过文件切片的方式，将大文件切片成小文件
2. 将小文件上传到服务器
3. 服务器接收到完小文件后，将小文件合并成大文件

# 二，三个步骤中的问题与处理方式

## 1. 文件切片

1，这里使用原生 html 的 <input type="file"> 元素来获取文件，并通过绑定 change 事件确保始终获取最新选择的文件对象：

```html
选择文件<input type="file" @change="handleFileChange">
```

在 chenge 事件的参数 event 中，可以通过 event.target.files 获取到文件对象列表，这里我们只需要获取其中的第一个文件对象，所以可以通过
event.target.files[0] 来获取到指定的文件对象。

```javascript
function handleFileChange(event) {
    console.log('event:', event)
    state.fileObj = event.target.files[0];

    // 切片
    sliceFileObj()
}
```

2，拿到文件对象后，我们需要将文件切片。
所谓的切片：就是对文件进行分割，即将文件分割成若干个小文件。这里我们使用原生的 File 对象的 slice 方法来进行切片：

```javascript
// 文件对象切片
const sliceFileObj = () => {
    const fileName = state.fileObj.name
    const fileSize = state.fileObj.size
    const fileType = state.fileObj.type

    let chunkSize = 1024 * 1024 * 2; // 每个切片的大小（2MB）
    let start = 0; // 切片的起始位置
    let chunk = 0; // 切片大小

    state.fileSliceList = []

    while (start < fileSize) {

        if (start + chunkSize <= fileSize) {
            state.fileSliceList.push({
                start: start,
                end: start + chunkSize,
                size: chunkSize,
                obj: state.fileObj.slice(start, start + chunkSize)
            })
        } else {
            state.fileSliceList.push({
                start: start,
                end: fileSize,
                size: fileSize - start,
                obj: state.fileObj.slice(start, fileSize - start)
            })
        }

        start += chunkSize
    }
}
```

这里我们将所有小切片放入到一个数组当中，方便后续使用。

## 2. 小文件上传

现在我们已经将大文件切片成了若干个小文件，接下来我们需要将这些小文件上传到服务器。
最简单的方法就是有多少个小文件就发送多少个请求：

```javascript
// 上传文件
const startUploadFile = async () => {
    state.fileSliceList.forEach(item => {
        const formData = new FormData();
        formData.append('file', item.chunk);
        formData.append('filename', item.fileName);
        formData.append('chunkSize', item.chunkSize.toString());

        uploadBigFileSliceApi(formData, start, chunkSize, fileSize).then(res => {
            console.log('response: ', response)
            if (response.data.code === 200) {
                // 文件上传完成
                state.percentage = 100;
                state.progressStatus = 'success'
            }
        })
    })
}
```

但这样有几个问题：

1. 相较于发送一个大文件，通过多次请求发送小文件会增加额外的网络传输开销
2. 由于网络原因，可能会导致小文件的上传顺序与切片顺序不一致，这样在服务器接收到所有小文件后，需要对小文件进行排序，再进行合并，这样会增加服务器的处理开销
3. 由于网络原因，尽管服务器收到了我们的小文件，但是无法保证每个小文件的完整性，时的 2 的问题扩大

因此在传输签文件之前，我们需要对小文件进行 hash 计算：

> 在文件分片上传过程中，对小文件计算hash值的主要目的是确保数据的完整性和一致性。
> 通过计算每个小文件的hash值，可以在上传和下载过程中验证文件是否被篡改或损坏。
> 如果某个小文件的hash值与预期的不一致，就可以立即发现数据的问题，从而确保数据的准确性和安全性。
> 这种数据完整性验证的机制可以在文件分片上传过程中提供额外的保障，帮助确保文件的完整性和可靠性。

1，计算文件的 hash 值

```javascript
function handleFileChange(event) {
    // ...

    // 计算 hash
    calculateHash()
}


const calculateHash = () => {
    // 分片 hash，直接读取文件内容来生成 md5 值
    state.fileSliceList.forEach((item) => {
        let sparkMD5 = new SparkMD5()
        let reader = new FileReader()
        reader.readAsText(item.obj)
        reader.onload = (event) => {
            console.log('event:', event)

            //获取文件MD5
            let str = event.target.result
            sparkMD5.append(str)
            item.hash = sparkMD5.end()
        }
    })
}
```

这里我们通过 FileReader 对象来读取文件内容，然后通过 SparkMD5 对象根据文件内容来计算文件的 hash 值。

2，上传分片文件
这里我们通过并发请求的方式来上传文件。
但是这个并发的数量应该是有限制的，并发数和分片数之间的关系是：并发数 <= 分片数。因为如果文件太大，分片数太多，那么并发数太多会导致服务器压力过大，甚至会导致服务器崩溃。

```javascript
const concurrentUpload = () => {
    let concurrent = 6 // 并发数
    let index = 0 // 当前上传的索引
    let len = fileSliceList.length // 文件切片的长度

    let promiseList = []

    while (index < len) {
        let promise = uploadFile(index)
        promiseList.push(promise)

        if (promiseList.length === concurrent || index === len - 1) {
            Promise.all(promiseList).then((res) => {
                console.log('res:', res)
            })

            promiseList = []
        }

        index++
    }
}
```

在后端，我们需要讲这些小分片保存下来：

```python
# 大文件分片上传
@csrf_exempt
def upload_big_file_slice(request):
    if request.method == 'POST':
        file = request.FILES['file']

        start = request.POST.get('start')
        end = request.POST.get('end')
        total = request.POST.get('size')
        index = request.POST.get('index')
        file = request.FILES.get('file')
        hash_value = request.POST.get('hash')
        file_name = request.POST.get('fileName')

        save_dir = os.path.join(BASE_DIR, 'static', 'uploadFiles', 'temp', 'files', f'{file_name.split(".")[0]}')
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
        with open(os.path.join(save_dir, f'{hash_value}-----{index}.part'), 'wb') as f:
            f.write(file.read())
        return JsonResponse({
            'code': 200,
            'status': 'success',
            'msg': '分片上传成功',
            'data': {
                'start': start,
                'end': end,
                'total': total,
                'index': index,
                'hash': hash_value,
                'fileName': file_name
            }
        })
    else:
        return JsonResponse({
            'code': 405,
            'msg': '请求方式错误',
            'data': None,
            'success': False
        })
```

在这之前，后端还应该对接收到的文件进行 hash 计算，然后与前端传过来的 hash 值进行比对，如果一致，说明文件完整，否则说明文件不完整。

## 3. 合并文件

合并文件主要就是后端的工作，这里前端只需要通过接口告诉后端要合并的文件名即可。

```python
# 合并大文件分片
@csrf_exempt
def merge_big_file_slice(request):
    if request.method == 'GET':
        file_name = request.GET.get('fileName', None)
        print(file_name)
        save_dir = os.path.join(BASE_DIR, 'static', 'uploadFiles', 'temp', 'files', f'{file_name.split(".")[0]}')
        if os.path.exists(save_dir):
            # 获取文件夹下的所有文件名
            file_list = os.listdir(save_dir)
            # 根据文件名中的 -----数字.part 进行排序
            file_list.sort(key=lambda x: int(x.split('-----')[-1].split('.')[0]))

            print(file_list)
            # 创建新文件
            with open(os.path.join(BASE_DIR, 'static', 'uploadFiles', 'temp', 'files', file_name), 'wb') as f:
                # 将分片文件内容写入新文件
                for file in file_list:
                    with open(os.path.join(save_dir, file), 'rb') as f1:
                        f.write(f1.read())

            # 合并完成后删除存放分片文件的文件夹
            for file in file_list:
                os.remove(os.path.join(save_dir, file))
            os.rmdir(save_dir)

        return JsonResponse({
            'code': 200,
            'status': 'success',
            'msg': '合并分片成功',
            'data': {
                'fileName': file_name
            }
        })
    else:
        return JsonResponse({
            'code': 405,
            'msg': '请求方式错误',
            'data': None,
            'success': False
        })
```

